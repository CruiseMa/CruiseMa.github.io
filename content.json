[{"title":"梯度下降的数学推导","date":"2017-02-12T07:07:58.000Z","path":"2017/02/12/梯度下降的数学推导/","text":"1.预备知识：偏导数及其几何意义","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"回归与梯度下降","date":"2017-02-08T11:04:58.000Z","path":"2017/02/08/回归与梯度下降/","text":"基于Andrew Ng（吴恩达）的机器学习课程 1.引入问题：房价预测假设有一个房屋销售记录表 我们将这些数据点画出来：横轴表示房屋面积，纵轴表示价格 给你一组这样的数据集，能否预测房屋面积和房价之间的关系？ 我们可以用一条直线去尽量准的拟合这些数据，然后如果有新的输入过来，我们可以在将直线上这个点对应的值返回，即高中学的“线性回归（regression）”方法。 2.学习过程首先声明一些概念和常用的符号： x代表输入变量，也称为特征（feature），在本例中代表房屋面积； y代表输出变量，有时也称为目标变量（target），在本例中代表房价； （x,y）表示一个样本，（xi,yi）代表第i个样本； 输入数据称为训练集（training set），在本例中代表房屋销售记录表。 下面是一个典型的机器学习的过程，首先给出一个训练集合，提供给学习算法，之后我们的算法会生成一个输出函数h，这个函数有能力对没有见过的新数据给出一个新的估计。 3.线性回归通常情况下许多回归问题都有多个输入特征，例如如果除了知道房子的大小之外，我们还知道房子的卧室数量： 那么，我们的训练集就可以有第二个特征，我们用 X1，X2..Xi 去描述 feature 里面的分量，比如 X1代表房子的面积，X2代表卧室数量， 等等，我们可以做出一个估计函数： 我们最终的目的就是要找到合适的参数值θ。令Xo=1，我们可以将函数h表示为： n表示特征的数目 程序需要一个机制去评估 h 函数选择的 θ 是否比较好，我们用一个损失函数（loss function），描述 h 函数不好的程度，称这个函数为 J 函数： J函数是对估计值h(i)与真实值 y(i)差的平方和作为错误估计，前面乘的 1/2 是为了在求导的时候，这个系数就不见了。 在选定线性回归模型后，只需要确定参数θ，就可以将模型用来预测。然而θ需要在 J(θ) 最小的情况下才能确定。因此问题归结为求极小值问题。 4.梯度下降法如何调整 θ 以使得 J(θ)取得最小值，使用梯度下降法（gradient descent ）。 梯度下降法是按下面的流程进行的： 首先对θ赋值，这个值可以是随机的，也可以让θ是一个全零的向量。 改变θ的值，使得J(θ)按梯度下降的方向进行减少。 对于单一的训练样本，这里给出了更新规则： 称为LMS更新规则（least mean squares 最小均方差），其中，α称为学习率，是一个能自己设定的常数，通常很小，下面还会讲到。 梯度下降法最大的问题是求得有可能是全局极小值，这与初始点的选取有关。 待续… 梯度方向由 J(θ)对 θ 的偏导数确定，由于求的是极小值，因此梯度方向是偏导数的反方向。 结果为","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]}]